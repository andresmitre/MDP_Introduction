{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "< [In Depth: MDP Wikipedia example](MDP-wikipedia.ipynb) | [In-Dept: MDP Exercise](MDP-2.ipynb) >\n",
    "\n"
    ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Decision Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Markov decision process (MDP) is a discrete time stochastic control process. It provides a mathematical framework for modeling decision making in situations where outcomes are partly random and partly under the control of a decision maker.\n",
    "At each time step, the process is in some state $S$, and the decision maker may choose any action a that is available in state $S$. The process responds at the next time step by randomly moving into a new state $s'$, and giving the decision maker a corresponding reward $R_a(S,S')$.\n",
    "\n",
    "The probability that the process moves into its new state $s'$ is influenced by the chosen action. Specifically, it is given by the state transition function $P_a(S,S')$. Thus, the next state $S'$ depends on the current state $S$ and the decision maker's action $a$. But given $S$ and $a$, it is conditionally independent of all previous states and actions; in other words, the state transitions of an MDP satisfies the Markov property.\n",
    "\n",
    "A Markov decision process is a 4-tuple $(S,A,P_a,R_a)$, where:\n",
    "\n",
    "$S$ is a finite set of states,\n",
    "\n",
    "$A$ is a finite set of actions (alternatively, $A_s$ is the finite set of actions available from state $S$\n",
    "\n",
    "$P_a (S,S') = P_r (S_t+1 = S';  S_t = S , a_t = a )$ is the probability that action $a$ in state $S$ at time $t$ will lead to state $S'$  at time $t + 1$,\n",
    "\n",
    "$R_a (S,S')$ is the immediate reward (or expected immediate reward) received after transitioning from state $S$ to state $S'$, due to action $a$"
]
},
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation\n",
    "\n",
    "The value function for the MDP is defined as:"
    ]
},
{
 "cell_type": "markdown",
 "metadata": {},
 "source": [
  "![](images/equation.png)"
 ]
},
{
 "cell_type": "markdown",
 "metadata": {},
 "source": [
  "###The policy\n",
  "The objective of this MDP is to find the optimum policy for the reward $+5$ intuitively starting from $S_0$ we can see that the best route to take are the actions $a_1, a_1, a_0$ respectivly.\n",
  "At each time step, the process is in some state $S$, and the decision maker may choose any action a that is available in state $S$. The process responds at the next time step by randomly moving into a new state $s'$, and giving the decision maker a corresponding reward $R_a(S,S')$.\n",
  "\n",
  "Breaking down the problem:\n",
  "\n",
  "Consider we start at the $S_0$, and we have the following vectors:\n",
  "$$V_1=\\begin{pmatrix}0 \\\\ 0 \\\\ 0 \\end{pmatrix}$$\n",
  "$$V_2=\\begin{pmatrix}0 \\\\ 0 \\\\ 0 \\end{pmatrix}$$\n",
  "\n",
  "We can either take action $a_0$ and have a probability of 1/2 to go to $S_1$ and other 1/2 to go back to $S_0$.\n",
  "According to the formula above we can get the value function from taking the two actions:and have a probability of 1/2 to go to $S_1$ and other 1/2 to go back to $S_0$.\n",
  "$$V_(1) = max_{a}\n",
  "$$a_0 : P_a(0,1)(R_a(0,1) + gamma V_i(S'))$$\n",
  "$$a_0 = {\\sum_{S'} = P_a(0,1)(R_a(S,S') + //gamma V_i(S'))}$$\n",
  ""
]
},
{
 "cell_type": "markdown",
 "metadata": {},
 "source": [
  "\n",
  "Consider the next example (figure example from [wikipedia](https://en.wikipedia.org/wiki/Markov_decision_process)):\n",
  "![](images/MDP.png)"
  ]
},
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model slope:     2.02720881036\n",
      "Model intercept: -4.99857708555\n"
     ]
    }
   ],
   "source": [
    "print(\"Inclinacion del modelo:    \", model.coef_[0])\n",
    "print(\"Intercepción del modelo:\", model.intercept_)\n",
    "Import library:"
   ]
  },
{
 "cell_type": "code",
 "execution_count": 1,
 "metadata": {
  "collapsed": true
 },
 "outputs": [],
 "source": [
  "%Numpy\n",
  "import numpy as np"
 ]
},
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``LinearRegression`` es mas poderoso que una *linea recta*. Maneja modelos lineales multidimensionales de la forma:\n",
    "$$\n",
    "y = a_0 + a_1 x_1 + a_2 x_2 + \\cdots\n",
    "$$\n",
    "Donde hay multiplos de valores de valores de $x$.\n",
    "\n",
    "multidimensionalmente, la regresión se dificulta para visualizar,  pero podemos observar los coeficientes mas optimos para ese modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "[ 1.5 -2.   1. ]\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.RandomState(1)\n",
    "X = 10 * rng.rand(100, 3)\n",
    "y = 0.5 + np.dot(X, [1.5, -2., 1.])\n",
    "\n",
    "model.fit(X, y)\n",
    "print(model.intercept_)\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funciones basicas polinomiales\n",
    "\n",
    "Para adaptar la regressión lineal a relaciones no lineales entre variables es usando ``PolynomialRegression``\n",
    "$$\n",
    "y = a_0 + a_1 x_1 + a_2 x_2 + a_3 x_3 + \\cdots\n",
    "$$\n",
    "Construimos $x_1, x_2, x_3,$ etc, desde nuestra entrada $x$.\n",
    "Entonces $x_n = f_n(x)$, donde $f_n()$ es una función que transforma nuestros datos.\n",
    "\n",
    "Ejemplo, si $f_n(x) = x^n$, nuestro modelo se convierte a una regresión polinial:\n",
    "$$\n",
    "y = a_0 + a_1 x + a_2 x^2 + a_3 x^3 + \\cdots\n",
    "$$"
    ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  2.,   4.,   8.],\n",
       "       [  3.,   9.,  27.],\n",
       "       [  4.,  16.,  64.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "x = np.array([2, 3, 4])\n",
    "poly = PolynomialFeatures(3, include_bias=False)\n",
    "poly.fit_transform(x[:, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "poly_model = make_pipeline(PolynomialFeatures(7),\n",
    "                           LinearRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos observar que podemos usar el modelo lineal, para clasificar relaciones mas complicadas entre $x$ y $y$. \n",
    "Por ejemplo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NAVIGATION-->\n",
    "< [In Depth: MDP Wikipedia example](MDP-wikipedia.ipynb) | [In-Dept: MDP Exercise](MDP-2.ipynb) >\n",
    "\n"
    ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
